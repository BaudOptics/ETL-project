{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sustainable-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "built-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "artistic-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs \n",
    "import pandas as pd\n",
    "import re\n",
    "from selenium import webdriver \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ignored-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "################ utility function\n",
    "def return_string(string, start_after_word,stop_before_word):\n",
    "    \"\"\"return part of string between 2 words \\\n",
    "    (string, start_after_word,stop_befor_word)\"\"\"\n",
    "    try:\n",
    "        if start_after_word==\"\":\n",
    "            start_address=0\n",
    "        else:\n",
    "            start_address=re.search(start_after_word,string).span()[1]\n",
    "        #print(start_address)\n",
    "        if stop_before_word==\"\":\n",
    "            stop_address=len(string)\n",
    "        else:\n",
    "            stop_address=re.search(stop_before_word,string).span()[0]\n",
    "        #print(stop_address)\n",
    "        my_string=string[start_address:stop_address]\n",
    "    except Exception as e:\n",
    "        # handle error\n",
    "        error=f\"_exception_: {type(e).__name__},</br> _arguments_: {e.args}\"\n",
    "        print(error)\n",
    "        my_string=None\n",
    "    return my_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caroline-result",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "###############filter function \n",
    "def heb_filter(soup_find):\n",
    "    \"\"\" function takes result of HEB scraping - soup.find_all and\n",
    "    transforms it to dataframe \"\"\"\n",
    "    my_result=soup_find\n",
    "    scrap_df=pd.DataFrame()\n",
    "    try:\n",
    "#       my_result=soup.body.find_all('a',id=re.compile('product-'))\n",
    "       \n",
    "        i=0\n",
    "        for record in my_result:\n",
    "            name=record.find('span',class_=re.compile('responsive')).text.strip()\n",
    "            size=return_string(name,\"Milk\",\"\")\n",
    "            json=eval(record.find('script',type=\"application/ld+json\").string)\n",
    "            id=json['id']\n",
    "            brand=json['brand']\n",
    "            category=json['category']\n",
    "            price=json['price']\n",
    "            search_string=record['aria-label'].strip()\n",
    "            features=return_string(search_string,\"Features:\",\"\")\n",
    "         #  rating=return_string(search_string,\"Rated\",\"stars\")\n",
    "            uomSalePrice=record.find('span',class_=re.compile('uomSalePrice')).text.strip()\n",
    "            image=record.find('img',attrs={\"data-src\":re.compile('prd-small')})['data-src']\n",
    "            if record.find('img',src=re.compile('coupon'))==None:\n",
    "                coupon=0\n",
    "            else:\n",
    "                coupon=1\n",
    "            #debug prints\n",
    "            #print(i) \n",
    "            #print (f'{name} \\n{size}\\n{json}\\n{id}\\n{brand}\\n{category}\\n{price}\\n{features}\\n{coupon}\\n{uomSalePrice}\\n{image}')\n",
    "            #print('___________________')\n",
    "            i+=1\n",
    "            scrap_df = scrap_df.append({'id':id,\n",
    "                                'name': name,\n",
    "                                'brand':brand,\n",
    "                                'size':size,\n",
    "                                'category':category,\n",
    "                                'price':price,\n",
    "                                'features':features,\n",
    "                                'coupon':coupon,\n",
    "                                'uomSalePrice':uomSalePrice,\n",
    "                                'image':image,\n",
    "                               }, ignore_index=True)\n",
    "        null_df=scrap_df[scrap_df.isna().any(axis=1)]\n",
    "    except Exception as e:\n",
    "        # handle error\n",
    "        print (f'{name} \\n{size}\\n{json}\\n{id}\\n{brand}\\n{category}\\n{price}\\n{features}\\n{coupon}\\n{uomSalePrice}\\n{image}')\n",
    "        error=f\"_exception_: {type(e).__name__},</br> _arguments_: {e.args}\"\n",
    "        print(error)\n",
    "        \n",
    "    return scrap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-amino",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
